{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3IEVK-KFxi5Z",
        "outputId": "3ee24982-2cf9-4dd1-c887-384830ead4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QXRh0DPiZRyG"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t9ALbbpmY9rm",
        "outputId": "82b695f6-9b50-440e-cf7d-326d39a1f160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "10.8401720524\n",
            "GPU (s):\n",
            "2.19899487495\n",
            "GPU speedup over CPU: 4x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kZwnnHQ49jSb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv('drive/day1_data_all.csv')\n",
        "X = data.drop(['status'],axis =1)\n",
        "Y = data.loc[:,'status']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IggnvXI99zOS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d-WfqrPe-X02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,random_state = 2018)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB1qIG4s-xEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "de4ec5a7-abeb-4dc7-8240-30c42434c896"
      },
      "cell_type": "code",
      "source": [
        "!pip install joblib\n",
        "!pip install pandas\n",
        "!pip install gbdt\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install imbalanced-learn\n",
        "!pip install -U git+https://github.com/scikit-learn-contrib/imbalanced-learn.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python2.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.22.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python2.7/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil->pandas) (1.11.0)\n",
            "Collecting gbdt\n",
            "  Using cached https://files.pythonhosted.org/packages/33/48/ad5e3c0356d85dd3c85006fe512e822e595a333f355dcb60be720cada9e1/gbdt-0.3.1.2.tar.gz\n",
            "Building wheels for collected packages: gbdt\n",
            "  Running setup.py bdist_wheel for gbdt ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e1/4e/77/9269956665f9f92ebb16eec5029c5dc5ac98be513a3a649c1b\n",
            "Successfully built gbdt\n",
            "Installing collected packages: gbdt\n",
            "Successfully installed gbdt-0.3.1.2\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python2.7/dist-packages (0.7.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from xgboost) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (from xgboost) (1.1.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python2.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (from lightgbm) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from lightgbm) (1.14.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from lightgbm) (0.20.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python2.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from imbalanced-learn) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python2.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python2.7/dist-packages (from imbalanced-learn) (0.20.1)\n",
            "Collecting git+https://github.com/scikit-learn-contrib/imbalanced-learn.git\n",
            "  Cloning https://github.com/scikit-learn-contrib/imbalanced-learn.git to /tmp/pip-req-build-qxV055\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from imbalanced-learn==0.5.0.dev0) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python2.7/dist-packages (from imbalanced-learn==0.5.0.dev0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python2.7/dist-packages (from imbalanced-learn==0.5.0.dev0) (0.20.1)\n",
            "Building wheels for collected packages: imbalanced-learn\n",
            "  Running setup.py bdist_wheel for imbalanced-learn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-e7cboU/wheels/6c/07/cf/38cb9b7cc9e6a0ac7648a80ec192b6f2d863405fb0049ac0ff\n",
            "Successfully built imbalanced-learn\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.5.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AnTRx9M8-nYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
        "# from sklearn.model_selection import    # no sklearn.grid_search\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upDO1zIJC7Kj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# k(5)折 + 标准化\n",
        "def k5_standard_unadjusted(a):\n",
        "  \n",
        "    estimators = [('scl', StandardScaler()), ('clf', a)]\n",
        "    pipe_model = Pipeline(estimators)\n",
        "    pipe_model.fit(X_train, y_train)  # print(pipe_lr.score(X_test, y_test))\n",
        "    scores = cross_val_score(estimator=pipe_model, X=X_test, y=y_test, cv=5, n_jobs=1)\n",
        "    print(scores.mean())\n",
        "    \n",
        "    \n",
        "def k5_standard(a,param_grid):\n",
        "  \n",
        "    estimators = [('scl', StandardScaler()), ('clf', a)]\n",
        "    pipe_model = Pipeline(estimators)\n",
        "    pipe_model.fit(X_train, y_train)  # print(pipe_lr.score(X_test, y_test))\n",
        "    \n",
        "    clf_gs = GridSearchCV(estimator=pipe_model,param_grid=param_grid,scoring='accuracy',cv=5,n_jobs=-1)\n",
        "    \n",
        "    scores = cross_val_score(estimator=pipe_model, X=X_test, y=y_test, cv=5, n_jobs=1)\n",
        "    print(scores.mean())    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XpTPGl_Gc2K6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "2c2e6b10-db32-4e56-8b5d-e56f28c35135"
      },
      "cell_type": "code",
      "source": [
        "# 逻辑回归\n",
        "t0 = time.time()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_range=[0.01,0.1,1]   # 0.0001,0.001,0.01,0.1,1,10,100,1000\n",
        "param_penalty=['l1','l2']\n",
        "parameters = [{'clf__C':param_range,'clf__penalty':param_penalty}]\n",
        "\n",
        "clf= Pipeline([('scl',StandardScaler()),('clf',LogisticRegression(random_state=2018))])\n",
        "\n",
        "gs_lr = GridSearchCV(estimator=clf,param_grid=parameters,scoring='accuracy',cv=5,n_jobs=-1)\n",
        "gs_lr = gs_lr.fit(X_train,y_train)\n",
        "# clf_accuracy_scores = cross_val_score(estimator=clf_gs,X=X,y=y,scoring='accuracy',cv=5)\n",
        "\n",
        "print(gs_lr.best_score_)\n",
        "print(gs_lr.best_params_)\n",
        "\n",
        "print (time.time() - t0)      \n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7932070934776074\n",
            "{'clf__penalty': 'l1', 'clf__C': 0.1}\n",
            "7.67769217491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, y, **fit_params).transform(X)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GjVCQJ1YC36Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "77bf184c-785a-4fac-d7cf-52cf372d085d"
      },
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "t0 = time.time()\n",
        "\n",
        "from sklearn.svm import SVC  \n",
        "\n",
        "pipe_svc = Pipeline([('scl', StandardScaler()), ('clf', SVC(random_state=2018))])\n",
        "param_range = [ 0.1, 1.0, 10.0, 100.0]   # , 1.0, 10.0, 100.0, 1000.0  # 0.0001, 0.001, 0.01, \n",
        "parameters = [\n",
        "            {'clf__C': param_range,'clf__kernel': ['linear']},\n",
        "            {'clf__C': param_range, 'clf__gamma': param_range, 'clf__kernel': ['rbf']}\n",
        "]\n",
        "\n",
        "gs_sm = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\n",
        "# 待： 两个cv  进度查看  这里没用val\n",
        "gs_sm = gs_sm.fit(X_train, y_train)\n",
        "\n",
        "print(gs_sm.best_score_)\n",
        "print(gs_sm.best_params_)\n",
        "\n",
        "# clf = gs.best_estimator_\n",
        "# print('Test accuracy: %.3f' % clf.score(X_test, y_test))\n",
        "\n",
        "print (time.time() - t0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7974150886684701\n",
            "{'clf__C': 0.1, 'clf__kernel': 'linear'}\n",
            "Test accuracy: 0.778\n",
            "1874.42206717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lC7RmrU1vXr0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "param_range 的前半部分已经试过，0.1最优，所以这里0.1最优。\n",
        "疑问：前两个param_range的区别"
      ]
    },
    {
      "metadata": {
        "id": "kXSoCWID5WD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 决策树\n",
        "t0 = time.time()\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "parameters = [\n",
        "    {'n_estimators':range(10,70,10)}\n",
        "]\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(random_state = 2018)\n",
        "\n",
        "gs_tr = GridSearchCV(clf,param_grid = parameters, scoring='accuracy',cv=5, n_jobs=-1)\n",
        "gs_tr = gs_tr.fit(X_train, y_train)\n",
        "\n",
        "print(gs_tr.best_score_)\n",
        "print(gs_tr.best_params_)\n",
        "\n",
        "print (time.time() - t0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tn_pBLpo24oy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#随机森林\n",
        "t0 = time.time()\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(random_state=2018)\n",
        "\n",
        "#在bootstap为True和False的情况下的参数组合\n",
        "parameters=[\n",
        "           {'n_estimators':[3,10,15],'max_depth':[1,2,3,4,5,6,7,None]},\n",
        "           {'bootstrap':[False],'n_estimators':[3,10],'max_depth':[1,2,3,4,5,6,7,None]}\n",
        "]\n",
        "\n",
        "gs_rf = GridSearchCV(estimator=rfc,param_grid=parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
        "gs_rf = cross_val_score(estimator=rfc_rf,X=X,y=y,scoring='accuracy',cv=5)\n",
        "gs_rf = gs_rf.fit(X_train, y_train)\n",
        "\n",
        "print(gs_rf.best_score_)\n",
        "print(gs_rf.best_params_)\n",
        "\n",
        "# print('CV clf f1 score:%.3f +/- %.3f'%(np.mean(rfc_f1_scores),np.std(rfc_f1_scores)))\n",
        "\n",
        "print (time.time() - t0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i_1NRGlB5AzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2068
        },
        "outputId": "dc9ef765-3c73-4a25-a487-a7ecb5d1c574"
      },
      "cell_type": "code",
      "source": [
        "# GBDT\n",
        "t0 = time.time()\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "\n",
        "parameters = [\n",
        "             {\n",
        "              'max_depth': range(5,50,5),\n",
        "              'max_features': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "             }\n",
        "]\n",
        "xlf = GradientBoostingClassifier(random_state = 2018)\n",
        "\n",
        "gs_gbdt = GridSearchCV(xlf, param_grid=parameters, scoring='accuracy', cv=5)\n",
        "gs_gbdt = gs_gbdt.fit(X_train, y_train)\n",
        "\n",
        "print(gs_gbdt.best_score_)\n",
        "print(gs_gbdt.best_params_)\n",
        "\n",
        "print (time.time() - t0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6fe0a0af0429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgs_gbdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgs_gbdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs_gbdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_gbdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[1;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1194\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dcvqRcGiEVLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "73e9d5f4-7e57-46f8-8373-ba71f1c0f1c5"
      },
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "t0 = time.time()\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "parameters = [\n",
        "    \n",
        "          { \n",
        "             'max_depth':range(3,10,2),\n",
        "             'min_child_weight':range(1,6,2)\n",
        "          }\n",
        "]\n",
        "xlf = xgb.XGBClassifier(n_estimators=200,random_state=2018)\n",
        "            \n",
        "gs_xgb = GridSearchCV(xlf, param_grid=parameters, scoring='accuracy', cv=5)\n",
        "gs_xgb = gs_xgb.fit(X_train, y_train)\n",
        "\n",
        "print(gs_xgb.best_score_)\n",
        "print(gs_xgb.best_params_)\n",
        "\n",
        "print (time.time() - t0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7892996693718064\n",
            "{'max_depth': 3, 'min_child_weight': 5}\n",
            "175.299245834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q_7_jOU5J94p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7938881f-4f17-44fe-9203-7ff96b5cc8fc"
      },
      "cell_type": "code",
      "source": [
        "# LightGBM\n",
        "t0 = time.time()\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "# train = lgb.Dataset(train_x, train_y)\n",
        "# valid = lgb.Dataset(valid_x, valid_y, reference=train)\n",
        "\n",
        "\n",
        "parameters = {\n",
        "              'max_depth': range(3,8,1),   #[15, 20, 25, 30, 35],\n",
        "              'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
        "              'num_leaves': range(15,50,5)\n",
        "}\n",
        "#               'feature_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
        "#               'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
        "#               'bagging_freq': [2, 4, 5, 6, 8],\n",
        "#               'lambda_l1': [0, 0.1, 0.4, 0.5, 0.6],\n",
        "#               'lambda_l2': [0, 10, 15, 35, 40],\n",
        "#               'cat_smooth': [1, 10, 15, 20, 35]}\n",
        "\n",
        "gbm = lgb.LGBMClassifier(boosting_type='gbdt',\n",
        "                         objective = 'binary',\n",
        "                         metric = 'auc',\n",
        "                         verbose = 0,\n",
        "                         learning_rate = 0.01,\n",
        "                         num_leaves = 35,\n",
        "                         feature_fraction=0.8,\n",
        "                         bagging_fraction= 0.9,\n",
        "                         bagging_freq= 8,\n",
        "                         lambda_l1= 0.6,\n",
        "                         lambda_l2= 0)\n",
        "\n",
        "gs_lgb = GridSearchCV(gbm, param_grid=parameters, scoring='accuracy', cv=5)\n",
        "gs_lgb.fit(X_train, y_train)\n",
        "\n",
        "print(gs.best_score_)\n",
        "print(gs.best_params_)\n",
        "    \n",
        "print (time.time() - t0)    \n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.796\n",
            "Best parameters set:\n",
            "230.358510017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ncl06euMeD9T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参考：\n",
        "\n",
        "https://www.jianshu.com/p/2c823a42afd9（逻辑回归）\n",
        "https://blog.csdn.net/wfei101/article/details/78691644（svm）\n",
        "https://www.jianshu.com/p/1100e333fcab（xgb、lgb）\n",
        "https://blog.csdn.net/weixin_43314414/article/details/85012474（007号同学）\n",
        "\n",
        "遇到问题："
      ]
    }
  ]
}